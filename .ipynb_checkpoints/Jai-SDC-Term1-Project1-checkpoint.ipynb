{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "from math import sqrt\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages below needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "kTestImagesRelativeInputPathDir = \"test_images/\"\n",
    "kTestImagesRelativeOutputPathDir = \"test_images_output/\"\n",
    "kTestVideosRelativeInputPathDir = \"test_videos/\"\n",
    "kTestVideosRelativeOutputPathDir = \"test_videos_output/\"\n",
    "\n",
    "# Global variable(s)\n",
    "\n",
    "global_previous_left_lane_bottom_roi_intersection_point = (0,0)\n",
    "global_previous_right_lane_bottom_roi_intersection_point = (0,0)\n",
    "\n",
    "# This boolean is used to determine if we need to produce intermediate image artifacts, after each processing operation like Gray Scaling etc.\n",
    "generateIntermediateArtifacts = False\n",
    "\n",
    "# Helper method(s)\n",
    "def get_region_of_interest_vertices(image):\n",
    "    xsize = image.shape[1]\n",
    "    ysize = image.shape[0]\n",
    "    y_offset = 42\n",
    "    left_bottom = [120, ysize]\n",
    "    right_bottom = [850, ysize]\n",
    "    left_top = [480, ysize/2 + y_offset]\n",
    "    right_top = [490, ysize/2 + y_offset]\n",
    "    region_of_interest_vertices = np.array([[left_top,right_top,right_bottom,left_bottom]], dtype=np.int32)\n",
    "    return region_of_interest_vertices\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n",
    "        \n",
    " try:\n",
    "    global global_previous_left_lane_bottom_roi_intersection_point\n",
    "    global global_previous_right_lane_bottom_roi_intersection_point\n",
    "    leftLaneLineMaxLength = 0\n",
    "    rightLaneLineMaxLength = 0\n",
    "    longestLeftLaneLine = (0,0,0,0)\n",
    "    longestRightLaneLine = (0,0,0,0)\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            dy = y2 - y1\n",
    "            dx = x2 - x1\n",
    "            slope = dy / dx\n",
    "            lineLength = sqrt(dy**2 + dx**2)\n",
    "            \n",
    "            if slope < 0:\n",
    "               if(lineLength > leftLaneLineMaxLength):\n",
    "                    leftLaneLineMaxLength = lineLength\n",
    "                    longestLeftLaneLine = line\n",
    "                    \n",
    "            else:\n",
    "               if(lineLength > rightLaneLineMaxLength):\n",
    "                    rightLaneLineMaxLength = lineLength\n",
    "                    longestRightLaneLine = line                \n",
    "    \n",
    "    region_of_interest_vertices = get_region_of_interest_vertices(img)\n",
    "    region_of_interest_left_top = region_of_interest_vertices[0][0]\n",
    "    region_of_interest_right_top = region_of_interest_vertices[0][1]\n",
    "    region_of_interest_right_bottom = region_of_interest_vertices[0][2]\n",
    "    region_of_interest_left_bottom = region_of_interest_vertices[0][3]\n",
    "    \n",
    "    region_of_interest_top_line = get_line(region_of_interest_left_top, region_of_interest_right_top)\n",
    "    region_of_interest_bottom_line = get_line(region_of_interest_left_bottom, region_of_interest_right_bottom)\n",
    "\n",
    "    longest_left_lane_line = get_line([longestLeftLaneLine[0][0],longestLeftLaneLine[0][1]],[longestLeftLaneLine[0][2],longestLeftLaneLine[0][3]])\n",
    "    \n",
    "    longest_right_lane_line = get_line([longestRightLaneLine[0][0],longestRightLaneLine[0][1]],[longestRightLaneLine[0][2],longestRightLaneLine[0][3]])\n",
    "    \n",
    "    top_left_intersection_point = intersection(region_of_interest_top_line, longest_left_lane_line)\n",
    "    bottom_left_intersection_point = intersection(region_of_interest_bottom_line, longest_left_lane_line)    \n",
    "    if global_previous_left_lane_bottom_roi_intersection_point == (0,0):\n",
    "        global_previous_left_lane_bottom_roi_intersection_point = bottom_left_intersection_point\n",
    "        \n",
    "    top_right_intersection_point = intersection(region_of_interest_top_line, longest_right_lane_line)\n",
    "    bottom_right_intersection_point = intersection(region_of_interest_bottom_line, longest_right_lane_line)\n",
    "    if global_previous_right_lane_bottom_roi_intersection_point == (0,0):\n",
    "        global_previous_right_lane_bottom_roi_intersection_point = bottom_right_intersection_point\n",
    "    \n",
    "    if (top_left_intersection_point and bottom_left_intersection_point and top_right_intersection_point and bottom_right_intersection_point):\n",
    "        cv2.line(img, tuple(top_left_intersection_point), tuple(global_previous_left_lane_bottom_roi_intersection_point), color, thickness)\n",
    "        cv2.line(img, tuple(top_right_intersection_point), tuple(global_previous_right_lane_bottom_roi_intersection_point), color, thickness)\n",
    "\n",
    "      \n",
    " except TypeError: \n",
    "        print(\"Ignoring sporadic type error as noise.\")\n",
    "    \n",
    "def get_line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return (int(x),int(y))\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1, λ=0):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def process_image(image):\n",
    "    currentTime = datetime.datetime.now()\n",
    "    currentTimeString = str(currentTime)\n",
    "    # Important to not modify the original image, but instead work on it's copy\n",
    "    original_image_copy = np.copy(image)\n",
    "    greyscale_image = grayscale(original_image_copy)    \n",
    "    gaussian_blurred_image = gaussian_blur(greyscale_image,5)\n",
    "    canny_image = canny(gaussian_blurred_image,50,150)\n",
    "    \n",
    "    xsize = canny_image.shape[1]\n",
    "    ysize = canny_image.shape[0]\n",
    "    y_offset = 42\n",
    "    left_bottom = [120, ysize]\n",
    "    right_bottom = [850, ysize]\n",
    "    left_top = [480, ysize/2 + y_offset]\n",
    "    right_top = [490, ysize/2 + y_offset]\n",
    "    region_of_interest_vertices = np.array([[left_top,right_top,right_bottom,left_bottom]], dtype=np.int32)\n",
    "    region_of_interest_image = region_of_interest(canny_image,region_of_interest_vertices)\n",
    "    hough_lines_image = hough_lines(region_of_interest_image, 2, np.pi/180, 15, 4, 10)\n",
    "    original_image_overlaid_with_lanes = weighted_img(hough_lines_image,original_image_copy)\n",
    "    \n",
    "    if generateIntermediateArtifacts == True:\n",
    "        original_image_copy_filename = kTestImagesRelativeOutputPathDir + currentTimeString + \"_1_original_image_copy.jpg\" \n",
    "        plt.imshow(original_image_copy,cmap='gray')\n",
    "        plt.savefig(original_image_copy_filename)\n",
    "        \n",
    "        greyscale_image_filename = kTestImagesRelativeOutputPathDir + currentTimeString + \"_2_grayscale_image.jpg\" \n",
    "        plt.imshow(greyscale_image,cmap='gray')\n",
    "        plt.savefig(greyscale_image_filename)\n",
    "        \n",
    "        gaussian_blurred_image_filename = kTestImagesRelativeOutputPathDir + currentTimeString + \"_3_gaussian_blurred_image.jpg\" \n",
    "        plt.imshow(gaussian_blurred_image,cmap='gray')\n",
    "        plt.savefig(gaussian_blurred_image_filename)\n",
    "        \n",
    "        canny_image_filename = kTestImagesRelativeOutputPathDir + currentTimeString + \"_4_canny_image.jpg\" \n",
    "        plt.imshow(canny_image,cmap='gray')\n",
    "        plt.savefig(canny_image_filename)\n",
    "        \n",
    "        region_of_interest_image_filename = kTestImagesRelativeOutputPathDir + currentTimeString + \"_5_region_of_interest_image.jpg\" \n",
    "        plt.imshow(region_of_interest_image,cmap='gray')\n",
    "        plt.savefig(region_of_interest_image_filename)\n",
    "        \n",
    "        hough_lines_image_filename = kTestImagesRelativeOutputPathDir + currentTimeString + \"_6_hough_lines_image.jpg\" \n",
    "        plt.imshow(hough_lines_image,cmap='gray')\n",
    "        plt.savefig(hough_lines_image_filename)       \n",
    "\n",
    "    return original_image_overlaid_with_lanes\n",
    "\n",
    "# # Using the Pipeline above to process image(s)\n",
    "generateIntermediateArtifacts = False\n",
    "testImagesInputDirectory = os.listdir(kTestImagesRelativeInputPathDir)\n",
    "for imageFile in testImagesInputDirectory:\n",
    "    if '.jpg' in imageFile:\n",
    "        global_previous_left_lane_bottom_roi_intersection_point = (0,0)\n",
    "        global_previous_right_lane_bottom_roi_intersection_point = (0,0)\n",
    "        input_file_relative_path = kTestImagesRelativeInputPathDir + imageFile\n",
    "        output_file_relative_path = kTestImagesRelativeOutputPathDir + imageFile\n",
    "        image_with_detected_lanes = process_image(mpimg.imread(input_file_relative_path))\n",
    "        plt.imshow(image_with_detected_lanes)\n",
    "        plt.savefig(output_file_relative_path)\n",
    "\n",
    "# # Using the Pipeline above to process video(s)\n",
    "generateIntermediateArtifacts = False\n",
    "testVideosInputDirectory = os.listdir(kTestVideosRelativeInputPathDir)\n",
    "for videoFile in testVideosInputDirectory:\n",
    "       if '.mp4' in videoFile:\n",
    "           global_previous_left_lane_bottom_roi_intersection_point = (0,0)\n",
    "           global_previous_right_lane_bottom_roi_intersection_point = (0,0)\n",
    "           input_videofile_relative_path = kTestVideosRelativeInputPathDir + videoFile\n",
    "           output_file_relative_path = kTestVideosRelativeOutputPathDir + videoFile\n",
    "           input_clip = VideoFileClip(input_videofile_relative_path)\n",
    "           output_clip = input_clip.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "           %time output_clip.write_videofile(output_file_relative_path, audio=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
